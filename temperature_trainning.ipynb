{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import imageio\n",
    "import PIL\n",
    "from PIL import ImageFile\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#from torch.nn import functional as F\n",
    "# import pretrainedmodels\n",
    "#import torch.optim as optim\n",
    "from sklearn.metrics import f1_score,accuracy_score,roc_auc_score\n",
    "import math\n",
    "import time\n",
    "#import albumentations\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scaler(array):\n",
    "    return np.log(array+0.01)\n",
    "\n",
    "\n",
    "def invScaler(array):\n",
    "    return np.exp(array) - 0.01\n",
    "\n",
    "\n",
    "def pad_to_shape(array, from_shape=160, to_shape=160, how=\"mirror\"):\n",
    "    padding = int( (to_shape - from_shape) / 2)\n",
    "    if how == \"zero\":\n",
    "        array_padded = np.pad(array, ((0,0),(padding,padding),(padding,padding),(0,0)), mode=\"constant\", constant_values=0)\n",
    "    elif how == \"mirror\":\n",
    "        array_padded = np.pad(array, ((0,0),(padding,padding),(padding,padding),(0,0)), mode=\"reflect\")\n",
    "    return array_padded\n",
    "\n",
    "\n",
    "def pred_to_rad(pred, from_shape=160, to_shape=160):\n",
    "    padding = int( (from_shape - to_shape) / 2)\n",
    "    return pred[::, padding:padding+to_shape, padding:padding+to_shape].copy()\n",
    "\n",
    "\n",
    "def data_preprocessing(X):\n",
    "    X = np.moveaxis(X, 0, -1)\n",
    "    X = X[np.newaxis, ::, ::, ::]\n",
    "    X = Scaler(X)\n",
    "    X = pad_to_shape(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def data_postprocessing(nwcst):\n",
    "    nwcst = np.squeeze(np.array(nwcst))\n",
    "    nwcst = invScaler(nwcst)\n",
    "    nwcst = pred_to_rad(nwcst)\n",
    "    nwcst = np.where(nwcst>0, nwcst, 0)\n",
    "    return nwcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            dataset_dict,\n",
    "            image_names,\n",
    "            batch_size\n",
    "    ):\n",
    "        self.keys = [name.strip() for name in image_names]\n",
    "        self.dataset = dataset_dict\n",
    "        self.bs = batch_size\n",
    "\n",
    "    def get_index(self,i):\n",
    "      x = []\n",
    "      for j in range(20):\n",
    "        try:\n",
    "          arr = np.array(self.dataset.get(self.keys[i+j]))\n",
    "        except:\n",
    "          print(i,j)\n",
    "        x.append(arr)\n",
    "      \n",
    "      x = data_preprocessing(np.stack(x,0))\n",
    "      #x = np.transpose(np.squeeze(x),(2,1,0)) \n",
    "      x = np.squeeze(x)\n",
    "      y = np.squeeze(data_preprocessing(np.array(self.dataset[self.keys[i+3]])[np.newaxis,:,:]))\n",
    "\n",
    "      return x.astype('float32'),y.astype('float32')\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "      X = []\n",
    "      Y = []\n",
    "\n",
    "      for i in range(index*self.bs,(index+1)*self.bs):\n",
    "        x,y = self.get_index(i)\n",
    "        X.append(x[np.newaxis,:])\n",
    "        Y.append(y[np.newaxis,:])\n",
    "\n",
    "      return X,Y\n",
    "        \n",
    "    def __len__(self):\n",
    "      return (len(self.keys) - 20)//self.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 file \"temperature_data_part.h5\" (mode r)>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "dataset_dict = h5py.File('temperature_data_part.h5', 'r')\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78888\n",
      "23000\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "with open('78888.txt','r') as f:\n",
    "  image_names = f.readlines()\n",
    "  # print(image_names)\n",
    "# file = open(\"file_key.txt\")\n",
    "# print(file.read())  \n",
    "\n",
    "image_names = [name for name in image_names if name[:4]>'2000']\n",
    "\n",
    "train_images = [name.strip() for name in image_names if name[:4] > '2000']\n",
    "val_images = [name.strip() for name in image_names if name[:4] > '2000'][:23000]\n",
    "# train_images = [name for name in tqdm(image_names) if \"2017\" not in name]\n",
    "# val_images = [name for name in tqdm(image_names) if name[0:4]==\"2017\"]\n",
    "\n",
    "print(len(train_images))\n",
    "print(len(val_images))\n",
    "# print(train_images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    dataset_dict=dataset_dict,\n",
    "    image_names=train_images,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    dataset_dict=dataset_dict,\n",
    "    image_names=val_images,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "def rainnet(input_shape=(160, 160, 20), mode=\"regression\"):\n",
    "\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    conv1f = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1f = Activation(\"relu\")(conv1f)\n",
    "    conv1s = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(conv1f)\n",
    "    conv1s = Activation(\"relu\")(conv1s)\n",
    "    conv1t = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(conv1s)\n",
    "    conv1t = Activation(\"relu\")(conv1t)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1t)\n",
    "\n",
    "    conv2f = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2f = Activation(\"relu\")(conv2f)\n",
    "    conv2s = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(conv2f)\n",
    "    conv2s = Activation(\"relu\")(conv2s)\n",
    "    conv2t = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(conv2s)\n",
    "    conv2t = Activation(\"relu\")(conv2t)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2t)\n",
    "\n",
    "    conv3f = Conv2D(256, 3, padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3f = Activation(\"relu\")(conv3f)\n",
    "    conv3s = Conv2D(256, 3, padding='same', kernel_initializer='he_normal')(conv3f)\n",
    "    conv3s = Activation(\"relu\")(conv3s)\n",
    "    conv3t = Conv2D(256, 3, padding='same', kernel_initializer='he_normal')(conv3s)\n",
    "    conv3t = Activation(\"relu\")(conv3t)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3t)\n",
    "\n",
    "    conv4f = Conv2D(512, 3, padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4f = Activation(\"relu\")(conv4f)\n",
    "    conv4s = Conv2D(512, 3, padding='same', kernel_initializer='he_normal')(conv4f)\n",
    "    conv4s = Activation(\"relu\")(conv4s)\n",
    "    conv4t = Conv2D(512, 3, padding='same', kernel_initializer='he_normal')(conv4s)\n",
    "    conv4t = Activation(\"relu\")(conv4t)\n",
    "    drop4 = Dropout(0.5)(conv4t)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5f = Conv2D(1024, 3, padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5f = Activation(\"relu\")(conv5f)\n",
    "    conv5s = Conv2D(1024, 3, padding='same', kernel_initializer='he_normal')(conv5f)\n",
    "    conv5s = Activation(\"relu\")(conv5s)\n",
    "    conv5t = Conv2D(1024, 3, padding='same', kernel_initializer='he_normal')(conv5s)\n",
    "    conv5t = Activation(\"relu\")(conv5t)\n",
    "    drop5 = Dropout(0.5)(conv5t)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(drop5), conv4t], axis=3)\n",
    "    conv6 = Conv2D(512, 3, padding='same', kernel_initializer='he_normal')(up6)\n",
    "    conv6 = Activation(\"relu\")(conv6)\n",
    "    conv6 = Conv2D(512, 3, padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    conv6 = Activation(\"relu\")(conv6)\n",
    "    conv6 = Conv2D(512, 3, padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    conv6 = Activation(\"relu\")(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3t], axis=3)\n",
    "    conv7 = Conv2D(256, 3, padding='same', kernel_initializer='he_normal')(up7)\n",
    "    conv7 = Activation(\"relu\")(conv7)\n",
    "    conv7 = Conv2D(256, 3, padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    conv7 = Activation(\"relu\")(conv7)\n",
    "    conv7 = Conv2D(256, 3, padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    conv7 = Activation(\"relu\")(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2t], axis=3)\n",
    "    conv8 = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(up8)\n",
    "    conv8 = Activation(\"relu\")(conv8)\n",
    "    conv8 = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    conv8 = Activation(\"relu\")(conv8)\n",
    "    conv8 = Conv2D(128, 3, padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    conv8 = Activation(\"relu\")(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1t], axis=3)\n",
    "    conv9 = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(up9)\n",
    "    conv9 = Activation(\"relu\")(conv9)\n",
    "    conv9 = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Activation(\"relu\")(conv9)\n",
    "    conv9 = Conv2D(64, 3, padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Activation(\"relu\")(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    \n",
    "    if mode == \"regression\":\n",
    "        outputs = Conv2D(1, 1, activation='relu')(conv9)\n",
    "    elif mode == \"segmentation\":\n",
    "        outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_model = rainnet()\n",
    "temperature_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),loss='log_cosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 160, 160, 20)]       0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 160, 160, 64)         11584     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 160, 160, 64)         0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 160, 160, 64)         36928     ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 160, 160, 64)         0         ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 160, 160, 64)         36928     ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 160, 160, 64)         0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 80, 80, 64)           0         ['activation_2[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 80, 80, 128)          73856     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 80, 80, 128)          0         ['conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 80, 80, 128)          147584    ['activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 80, 80, 128)          0         ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 80, 80, 128)          147584    ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 80, 80, 128)          0         ['conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 40, 40, 128)          0         ['activation_5[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 40, 40, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 40, 40, 256)          0         ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 40, 40, 256)          590080    ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 40, 40, 256)          0         ['conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 40, 40, 256)          590080    ['activation_7[0][0]']        \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 40, 40, 256)          0         ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 20, 20, 256)          0         ['activation_8[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 20, 20, 512)          1180160   ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 20, 20, 512)          0         ['conv2d_9[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 20, 20, 512)          2359808   ['activation_9[0][0]']        \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 20, 20, 512)          0         ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 20, 20, 512)          2359808   ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 20, 20, 512)          0         ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 20, 20, 512)          0         ['activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 10, 10, 512)          0         ['dropout[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 10, 10, 1024)         4719616   ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 10, 10, 1024)         0         ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 10, 10, 1024)         9438208   ['activation_12[0][0]']       \n",
      "                                                                                                  \n",
      " activation_13 (Activation)  (None, 10, 10, 1024)         0         ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 10, 10, 1024)         9438208   ['activation_13[0][0]']       \n",
      "                                                                                                  \n",
      " activation_14 (Activation)  (None, 10, 10, 1024)         0         ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 10, 10, 1024)         0         ['activation_14[0][0]']       \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 20, 20, 1024)         0         ['dropout_1[0][0]']           \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 20, 20, 1536)         0         ['up_sampling2d[0][0]',       \n",
      "                                                                     'activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 20, 20, 512)          7078400   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " activation_15 (Activation)  (None, 20, 20, 512)          0         ['conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 20, 20, 512)          2359808   ['activation_15[0][0]']       \n",
      "                                                                                                  \n",
      " activation_16 (Activation)  (None, 20, 20, 512)          0         ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 20, 20, 512)          2359808   ['activation_16[0][0]']       \n",
      "                                                                                                  \n",
      " activation_17 (Activation)  (None, 20, 20, 512)          0         ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 40, 40, 512)          0         ['activation_17[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 40, 40, 768)          0         ['up_sampling2d_1[0][0]',     \n",
      " )                                                                   'activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 40, 40, 256)          1769728   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " activation_18 (Activation)  (None, 40, 40, 256)          0         ['conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 40, 40, 256)          590080    ['activation_18[0][0]']       \n",
      "                                                                                                  \n",
      " activation_19 (Activation)  (None, 40, 40, 256)          0         ['conv2d_19[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 40, 40, 256)          590080    ['activation_19[0][0]']       \n",
      "                                                                                                  \n",
      " activation_20 (Activation)  (None, 40, 40, 256)          0         ['conv2d_20[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 80, 80, 256)          0         ['activation_20[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 80, 80, 384)          0         ['up_sampling2d_2[0][0]',     \n",
      " )                                                                   'activation_5[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 80, 80, 128)          442496    ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " activation_21 (Activation)  (None, 80, 80, 128)          0         ['conv2d_21[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 80, 80, 128)          147584    ['activation_21[0][0]']       \n",
      "                                                                                                  \n",
      " activation_22 (Activation)  (None, 80, 80, 128)          0         ['conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 80, 80, 128)          147584    ['activation_22[0][0]']       \n",
      "                                                                                                  \n",
      " activation_23 (Activation)  (None, 80, 80, 128)          0         ['conv2d_23[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 160, 160, 128)        0         ['activation_23[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 160, 160, 192)        0         ['up_sampling2d_3[0][0]',     \n",
      " )                                                                   'activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 160, 160, 64)         110656    ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " activation_24 (Activation)  (None, 160, 160, 64)         0         ['conv2d_24[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 160, 160, 64)         36928     ['activation_24[0][0]']       \n",
      "                                                                                                  \n",
      " activation_25 (Activation)  (None, 160, 160, 64)         0         ['conv2d_25[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 160, 160, 64)         36928     ['activation_25[0][0]']       \n",
      "                                                                                                  \n",
      " activation_26 (Activation)  (None, 160, 160, 64)         0         ['conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 160, 160, 2)          1154      ['activation_26[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 160, 160, 1)          3         ['conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 47096837 (179.66 MB)\n",
      "Trainable params: 47096837 (179.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "temperature_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 True [(None, 160, 160, 20)]\n",
      "conv2d True (None, 160, 160, 64)\n",
      "activation True (None, 160, 160, 64)\n",
      "conv2d_1 True (None, 160, 160, 64)\n",
      "activation_1 True (None, 160, 160, 64)\n",
      "conv2d_2 True (None, 160, 160, 64)\n",
      "activation_2 True (None, 160, 160, 64)\n",
      "max_pooling2d True (None, 80, 80, 64)\n",
      "conv2d_3 True (None, 80, 80, 128)\n",
      "activation_3 True (None, 80, 80, 128)\n",
      "conv2d_4 True (None, 80, 80, 128)\n",
      "activation_4 True (None, 80, 80, 128)\n",
      "conv2d_5 True (None, 80, 80, 128)\n",
      "activation_5 True (None, 80, 80, 128)\n",
      "max_pooling2d_1 True (None, 40, 40, 128)\n",
      "conv2d_6 True (None, 40, 40, 256)\n",
      "activation_6 True (None, 40, 40, 256)\n",
      "conv2d_7 True (None, 40, 40, 256)\n",
      "activation_7 True (None, 40, 40, 256)\n",
      "conv2d_8 True (None, 40, 40, 256)\n",
      "activation_8 True (None, 40, 40, 256)\n",
      "max_pooling2d_2 True (None, 20, 20, 256)\n",
      "conv2d_9 True (None, 20, 20, 512)\n",
      "activation_9 True (None, 20, 20, 512)\n",
      "conv2d_10 True (None, 20, 20, 512)\n",
      "activation_10 True (None, 20, 20, 512)\n",
      "conv2d_11 True (None, 20, 20, 512)\n",
      "activation_11 True (None, 20, 20, 512)\n",
      "dropout True (None, 20, 20, 512)\n",
      "max_pooling2d_3 True (None, 10, 10, 512)\n",
      "conv2d_12 True (None, 10, 10, 1024)\n",
      "activation_12 True (None, 10, 10, 1024)\n",
      "conv2d_13 True (None, 10, 10, 1024)\n",
      "activation_13 True (None, 10, 10, 1024)\n",
      "conv2d_14 True (None, 10, 10, 1024)\n",
      "activation_14 True (None, 10, 10, 1024)\n",
      "dropout_1 True (None, 10, 10, 1024)\n",
      "up_sampling2d True (None, 20, 20, 1024)\n",
      "concatenate True (None, 20, 20, 1536)\n",
      "conv2d_15 True (None, 20, 20, 512)\n",
      "activation_15 True (None, 20, 20, 512)\n",
      "conv2d_16 True (None, 20, 20, 512)\n",
      "activation_16 True (None, 20, 20, 512)\n",
      "conv2d_17 True (None, 20, 20, 512)\n",
      "activation_17 True (None, 20, 20, 512)\n",
      "up_sampling2d_1 True (None, 40, 40, 512)\n",
      "concatenate_1 True (None, 40, 40, 768)\n",
      "conv2d_18 True (None, 40, 40, 256)\n",
      "activation_18 True (None, 40, 40, 256)\n",
      "conv2d_19 True (None, 40, 40, 256)\n",
      "activation_19 True (None, 40, 40, 256)\n",
      "conv2d_20 True (None, 40, 40, 256)\n",
      "activation_20 True (None, 40, 40, 256)\n",
      "up_sampling2d_2 True (None, 80, 80, 256)\n",
      "concatenate_2 True (None, 80, 80, 384)\n",
      "conv2d_21 True (None, 80, 80, 128)\n",
      "activation_21 True (None, 80, 80, 128)\n",
      "conv2d_22 True (None, 80, 80, 128)\n",
      "activation_22 True (None, 80, 80, 128)\n",
      "conv2d_23 True (None, 80, 80, 128)\n",
      "activation_23 True (None, 80, 80, 128)\n",
      "up_sampling2d_3 True (None, 160, 160, 128)\n",
      "concatenate_3 True (None, 160, 160, 192)\n",
      "conv2d_24 True (None, 160, 160, 64)\n",
      "activation_24 True (None, 160, 160, 64)\n",
      "conv2d_25 True (None, 160, 160, 64)\n",
      "activation_25 True (None, 160, 160, 64)\n",
      "conv2d_26 True (None, 160, 160, 64)\n",
      "activation_26 True (None, 160, 160, 64)\n",
      "conv2d_27 True (None, 160, 160, 2)\n",
      "conv2d_28 True (None, 160, 160, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in temperature_model.layers:\n",
    "    print(layer.name, layer.trainable, layer.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 5.3509e-04\n",
      "Epoch 1: val_loss improved from inf to 0.00012, saving model to model_weight.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78868/78868 [==============================] - 105077s 1s/step - loss: 5.3509e-04 - val_loss: 1.1809e-04\n",
      "Epoch 2/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 3.5340e-05\n",
      "Epoch 2: val_loss improved from 0.00012 to 0.00001, saving model to model_weight.h5\n",
      "78868/78868 [==============================] - 104048s 1s/step - loss: 3.5340e-05 - val_loss: 6.9330e-06\n",
      "Epoch 3/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 2.1547e-05\n",
      "Epoch 3: val_loss did not improve from 0.00001\n",
      "78868/78868 [==============================] - 103386s 1s/step - loss: 2.1547e-05 - val_loss: 3.9208e-05\n",
      "Epoch 4/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.7889e-05\n",
      "Epoch 4: val_loss did not improve from 0.00001\n",
      "78868/78868 [==============================] - 133917s 2s/step - loss: 1.7889e-05 - val_loss: 7.4515e-06\n",
      "Epoch 5/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.6108e-05\n",
      "Epoch 5: val_loss improved from 0.00001 to 0.00000, saving model to model_weight.h5\n",
      "78868/78868 [==============================] - 140678s 2s/step - loss: 1.6108e-05 - val_loss: 3.6842e-06\n",
      "Epoch 6/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.5403e-05\n",
      "Epoch 6: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 141959s 2s/step - loss: 1.5403e-05 - val_loss: 1.3876e-05\n",
      "Epoch 7/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.4483e-05\n",
      "Epoch 7: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 141943s 2s/step - loss: 1.4483e-05 - val_loss: 8.2550e-06\n",
      "Epoch 8/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.3343e-05\n",
      "Epoch 8: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 142333s 2s/step - loss: 1.3343e-05 - val_loss: 2.8108e-05\n",
      "Epoch 9/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.2484e-05\n",
      "Epoch 9: val_loss improved from 0.00000 to 0.00000, saving model to model_weight.h5\n",
      "78868/78868 [==============================] - 142262s 2s/step - loss: 1.2484e-05 - val_loss: 2.7461e-06\n",
      "Epoch 10/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.1828e-05\n",
      "Epoch 10: val_loss improved from 0.00000 to 0.00000, saving model to model_weight.h5\n",
      "78868/78868 [==============================] - 140453s 2s/step - loss: 1.1828e-05 - val_loss: 2.5818e-06\n",
      "Epoch 11/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.0988e-05\n",
      "Epoch 11: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 142858s 2s/step - loss: 1.0988e-05 - val_loss: 3.2757e-06\n",
      "Epoch 12/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.0627e-05\n",
      "Epoch 12: val_loss improved from 0.00000 to 0.00000, saving model to model_weight.h5\n",
      "78868/78868 [==============================] - 125982s 2s/step - loss: 1.0627e-05 - val_loss: 2.4145e-06\n",
      "Epoch 13/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.0278e-05\n",
      "Epoch 13: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 121701s 2s/step - loss: 1.0278e-05 - val_loss: 2.7268e-06\n",
      "Epoch 14/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.1155e-05\n",
      "Epoch 14: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 120064s 2s/step - loss: 1.1155e-05 - val_loss: 4.1485e-06\n",
      "Epoch 15/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.0489e-05\n",
      "Epoch 15: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 119749s 2s/step - loss: 1.0489e-05 - val_loss: 7.7152e-06\n",
      "Epoch 16/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 1.1156e-05\n",
      "Epoch 16: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 119747s 2s/step - loss: 1.1156e-05 - val_loss: 2.8430e-05\n",
      "Epoch 17/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 9.7242e-06\n",
      "Epoch 17: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 119486s 2s/step - loss: 9.7242e-06 - val_loss: 5.3024e-06\n",
      "Epoch 18/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 9.4393e-06\n",
      "Epoch 18: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 119633s 2s/step - loss: 9.4393e-06 - val_loss: 6.6266e-06\n",
      "Epoch 19/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 8.8814e-06\n",
      "Epoch 19: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 119788s 2s/step - loss: 8.8814e-06 - val_loss: 6.1413e-06\n",
      "Epoch 20/20\n",
      "78868/78868 [==============================] - ETA: 0s - loss: 8.8965e-06\n",
      "Epoch 20: val_loss did not improve from 0.00000\n",
      "78868/78868 [==============================] - 117662s 1s/step - loss: 8.8965e-06 - val_loss: 3.1661e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c2c9b082e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(x=train_dataset, epochs=10)\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'model_weight.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10, monitor='val_loss', mode='min', restore_best_weights=True\n",
    ")\n",
    "\n",
    "temperature_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=20,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
